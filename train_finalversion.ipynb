{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDHGOeh4v0G9",
        "outputId": "3b7b5b0f-e542-4b10-d69a-df04d2a0859f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d2VxH0tWrT1t"
      },
      "outputs": [],
      "source": [
        "def image_segmentation(data):\n",
        "\tprint(\"\\n........Program Initiated.......\\n\")\n",
        "\t#src_img = cv2.imread(data, cv2.IMREAD_GRAYSCALE)\n",
        "\tfor img in data:\n",
        "\t\torig_height, orig_width = img.shape\n",
        "\n",
        "\t\tprint(\"\\n Resizing Image........\")\n",
        "\t\twidth = 128\n",
        "\t\theight = int(width * orig_height / orig_width)\n",
        "\t\tsrc_img = cv2.resize(img, dsize=(width, height), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "\t\tprint(\"#---------Image Info:--------#\")\n",
        "\t\tprint(\"\\tHeight =\", height, \"\\n\\tWidth =\", width)\n",
        "\t\tPIXEL_SET = 255\n",
        "\t\tkernel_size = 21\n",
        "\t\tnormalized_mean = 20\n",
        "\t\tbin_img = cv2.adaptiveThreshold(img, PIXEL_SET, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, kernel_size,\n",
        "\t\t\t\t\t\t\t\t\t\tnormalized_mean)\n",
        "\n",
        "\t\tprint(\"Noise Removal\")\n",
        "\t\tkernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "\t\tfinal_thr = cv2.morphologyEx(bin_img, cv2.MORPH_CLOSE, kernel)\n",
        "\t\tcontr_retrival = final_thr.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "r-ZcHcf7rems",
        "outputId": "1a8c87d3-e194-4823-bc7d-e75c24c1b57a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: patool in /usr/local/lib/python3.7/dist-packages (1.12)\n",
            "patool: Extracting drive/MyDrive/data.rar ...\n",
            "patool: running /usr/bin/unrar x -- /content/drive/MyDrive/data.rar\n",
            "patool:     with cwd='./Unpack_gt21b3jd'\n",
            "patool: ... drive/MyDrive/data.rar extracted to `data' (local file exists).\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'data'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "!pip3 install patool\n",
        "import patoolib\n",
        "patoolib.extract_archive(\"drive/MyDrive/data.rar\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAYvu0Ax4T8y",
        "outputId": "95187975-6834-4c21-d973-f0c38d6b1ce6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "201496\n",
            "(201496,)\n",
            "(201496, 45, 45)\n",
            "['1' 'sin' ')' ... ')' '1' 'log']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "path = 'extracted_images'\n",
        "#files=os.listdir(path)\n",
        "\n",
        "use_number = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "use_symbol = ['+', '-', 'times', 'div', '!', '(', ')', 'pi', 'log', 'sin', 'cos', 'tan']\n",
        "\n",
        "def load_images_from_folder(dir):\n",
        "    train_data=[]\n",
        "    label = []\n",
        "    for label_name in os.listdir(dir):\n",
        "      if (label_name not in use_number) and (label_name not in use_symbol):\n",
        "        continue\n",
        "      folder = dir + \"/\" + label_name\n",
        "      for filename in os.listdir(folder):\n",
        "          #print(os.path.join(folder,filename))\n",
        "          img = cv2.imread(os.path.join(folder,filename),cv2.IMREAD_GRAYSCALE)\n",
        "          img = ~img\n",
        "          train_data.append(img)\n",
        "          label.append(label_name)\n",
        "          if img is not None:\n",
        "              ret,thresh=cv2.threshold(img,127,255,cv2.THRESH_BINARY)\n",
        "              ret,ctrs,ret=cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n",
        "              cnt=sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[0])\n",
        "              w=int(28)\n",
        "              h=int(28)\n",
        "              maxi=0\n",
        "              for c in cnt:\n",
        "                  x,y,w,h=cv2.boundingRect(c)\n",
        "                  maxi=max(w*h,maxi)\n",
        "                  if maxi==w*h:\n",
        "                      x_max=x\n",
        "                      y_max=y\n",
        "                      w_max=w\n",
        "                      h_max=h\n",
        "              im_crop= thresh[y_max:y_max+h_max+10, x_max:x_max+w_max+10]\n",
        "              im_resize = cv2.resize(im_crop,(28,28))\n",
        "              im_resize=np.reshape(im_resize,(784,1))\n",
        "              train_data.append(im_resize)\n",
        "\n",
        "    return train_data, label\n",
        "\n",
        "data, label = load_images_from_folder(path)\n",
        "print(len(label))\n",
        "\n",
        "\n",
        "print(np.array(label).shape)\n",
        "print(np.array(data).shape)\n",
        "\n",
        "shuffle_img, shuffle_label = sklearn.utils.shuffle(np.array(data), np.array(label))\n",
        "\n",
        "print(shuffle_label)\n",
        "\n",
        "\n",
        "#image_segmentation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 739
        },
        "id": "S8CoDkzLPblU",
        "outputId": "75e1430e-bd76-45d6-b3f2-7e7af4dfdec9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100000, 45, 45)\n",
            "(100000,)\n",
            "!          635\n",
            "(         7052\n",
            ")         7181\n",
            "+        12568\n",
            "-        16934\n",
            "0         3370\n",
            "1        12940\n",
            "2        12983\n",
            "3         5502\n",
            "4         3700\n",
            "5         1768\n",
            "6         1514\n",
            "7         1395\n",
            "8         1552\n",
            "9         1884\n",
            "cos       1410\n",
            "div        459\n",
            "log       1001\n",
            "pi        1170\n",
            "sin       2176\n",
            "tan       1202\n",
            "times     1604\n",
            "dtype: int64\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 2160x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "X, y = resample(shuffle_img, shuffle_label, n_samples = 100000)\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (30, 8)\n",
        "labels = pd.DataFrame(y)\n",
        "count = labels.value_counts().sort_index()\n",
        "print(count)\n",
        "cnt = count.to_dict()\n",
        "count = pd.Series(cnt)\n",
        "bar = count.plot(kind='bar')\n",
        "bar.set_xticklabels(labels = count.index)\n",
        "plt.xticks(rotation = 0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7nvMXKogOeD",
        "outputId": "e3578d5c-be81-4d40-d09e-f64496dab9d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'!': 0, '(': 1, ')': 2, '+': 3, '-': 4, '0': 5, '1': 6, '2': 7, '3': 8, '4': 9, '5': 10, '6': 11, '7': 12, '8': 13, '9': 14, 'cos': 15, 'div': 16, 'log': 17, 'pi': 18, 'sin': 19, 'tan': 20, 'times': 21}\n",
            "[ 6 19  2 ...  2  6 17]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "labelencoder = LabelEncoder()\n",
        "labelencoder.fit(np.ravel(shuffle_label))\n",
        "label_encoded = labelencoder.transform(np.ravel(shuffle_label))\n",
        "\n",
        "#label_encoded_t = labelencoder.transform(np.ravel(test_label))\n",
        "\n",
        "encoded = tf.keras.utils.to_categorical(label_encoded, num_classes=22)\n",
        "#test_encoded = tf.keras.utils.to_categorical(label_encoded_t, num_classes=6)\n",
        "\n",
        "\n",
        "le_name_mapping = dict(zip(labelencoder.classes_, labelencoder.transform(labelencoder.classes_)))\n",
        "print(le_name_mapping)\n",
        "print(label_encoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agXvGhCfeyYL",
        "outputId": "24983a72-a103-49be-adb6-4382177ed1f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "Epoch 1/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.2489 - accuracy: 0.9286\n",
            "Epoch 1: val_loss improved from inf to 0.12613, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.2489 - accuracy: 0.9286 - val_loss: 0.1261 - val_accuracy: 0.9633 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.1009 - accuracy: 0.9700\n",
            "Epoch 2: val_loss improved from 0.12613 to 0.09559, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.1009 - accuracy: 0.9700 - val_loss: 0.0956 - val_accuracy: 0.9708 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0754 - accuracy: 0.9767\n",
            "Epoch 3: val_loss improved from 0.09559 to 0.07796, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0754 - accuracy: 0.9767 - val_loss: 0.0780 - val_accuracy: 0.9778 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9811\n",
            "Epoch 4: val_loss improved from 0.07796 to 0.05828, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0603 - accuracy: 0.9811 - val_loss: 0.0583 - val_accuracy: 0.9809 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0497 - accuracy: 0.9839\n",
            "Epoch 5: val_loss improved from 0.05828 to 0.04731, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0497 - accuracy: 0.9839 - val_loss: 0.0473 - val_accuracy: 0.9857 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.0422 - accuracy: 0.9861\n",
            "Epoch 6: val_loss did not improve from 0.04731\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0422 - accuracy: 0.9861 - val_loss: 0.0514 - val_accuracy: 0.9839 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9880\n",
            "Epoch 7: val_loss improved from 0.04731 to 0.03829, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0365 - accuracy: 0.9880 - val_loss: 0.0383 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "2516/2519 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9894\n",
            "Epoch 8: val_loss improved from 0.03829 to 0.03468, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0316 - accuracy: 0.9894 - val_loss: 0.0347 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0282 - accuracy: 0.9906\n",
            "Epoch 9: val_loss improved from 0.03468 to 0.03244, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0282 - accuracy: 0.9906 - val_loss: 0.0324 - val_accuracy: 0.9894 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0253 - accuracy: 0.9913\n",
            "Epoch 10: val_loss improved from 0.03244 to 0.02997, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0252 - accuracy: 0.9913 - val_loss: 0.0300 - val_accuracy: 0.9903 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0218 - accuracy: 0.9923\n",
            "Epoch 11: val_loss improved from 0.02997 to 0.02343, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0218 - accuracy: 0.9923 - val_loss: 0.0234 - val_accuracy: 0.9922 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0201 - accuracy: 0.9932\n",
            "Epoch 12: val_loss did not improve from 0.02343\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0201 - accuracy: 0.9931 - val_loss: 0.0302 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0186 - accuracy: 0.9934\n",
            "Epoch 13: val_loss improved from 0.02343 to 0.02307, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0186 - accuracy: 0.9934 - val_loss: 0.0231 - val_accuracy: 0.9916 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9944\n",
            "Epoch 14: val_loss improved from 0.02307 to 0.01896, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0164 - accuracy: 0.9944 - val_loss: 0.0190 - val_accuracy: 0.9936 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9948\n",
            "Epoch 15: val_loss did not improve from 0.01896\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0150 - accuracy: 0.9948 - val_loss: 0.0193 - val_accuracy: 0.9932 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.0141 - accuracy: 0.9951\n",
            "Epoch 16: val_loss improved from 0.01896 to 0.01584, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0141 - accuracy: 0.9951 - val_loss: 0.0158 - val_accuracy: 0.9951 - lr: 0.0010\n",
            "Epoch 17/30\n",
            "2517/2519 [============================>.] - ETA: 0s - loss: 0.0132 - accuracy: 0.9954\n",
            "Epoch 17: val_loss improved from 0.01584 to 0.01565, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0132 - accuracy: 0.9954 - val_loss: 0.0157 - val_accuracy: 0.9952 - lr: 0.0010\n",
            "Epoch 18/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9954\n",
            "Epoch 18: val_loss improved from 0.01565 to 0.01533, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 0.0153 - val_accuracy: 0.9948 - lr: 0.0010\n",
            "Epoch 19/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0117 - accuracy: 0.9961\n",
            "Epoch 19: val_loss improved from 0.01533 to 0.01434, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0117 - accuracy: 0.9961 - val_loss: 0.0143 - val_accuracy: 0.9959 - lr: 0.0010\n",
            "Epoch 20/30\n",
            "2511/2519 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9964\n",
            "Epoch 20: val_loss did not improve from 0.01434\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0103 - accuracy: 0.9964 - val_loss: 0.0217 - val_accuracy: 0.9933 - lr: 0.0010\n",
            "Epoch 21/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0107 - accuracy: 0.9964\n",
            "Epoch 21: val_loss did not improve from 0.01434\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.0147 - val_accuracy: 0.9956 - lr: 0.0010\n",
            "Epoch 22/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0103 - accuracy: 0.9967\n",
            "Epoch 22: val_loss improved from 0.01434 to 0.01383, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0138 - val_accuracy: 0.9956 - lr: 0.0010\n",
            "Epoch 23/30\n",
            "2517/2519 [============================>.] - ETA: 0s - loss: 0.0096 - accuracy: 0.9968\n",
            "Epoch 23: val_loss did not improve from 0.01383\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0095 - accuracy: 0.9968 - val_loss: 0.0163 - val_accuracy: 0.9952 - lr: 0.0010\n",
            "Epoch 24/30\n",
            "2514/2519 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9969\n",
            "Epoch 24: val_loss improved from 0.01383 to 0.01380, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0097 - accuracy: 0.9969 - val_loss: 0.0138 - val_accuracy: 0.9956 - lr: 0.0010\n",
            "Epoch 25/30\n",
            "2508/2519 [============================>.] - ETA: 0s - loss: 0.0080 - accuracy: 0.9973\n",
            "Epoch 25: val_loss did not improve from 0.01380\n",
            "\n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0080 - accuracy: 0.9973 - val_loss: 0.0203 - val_accuracy: 0.9937 - lr: 0.0010\n",
            "Epoch 26/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0030 - accuracy: 0.9993\n",
            "Epoch 26: val_loss improved from 0.01380 to 0.00645, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0065 - val_accuracy: 0.9985 - lr: 3.0000e-04\n",
            "Epoch 27/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9994\n",
            "Epoch 27: val_loss improved from 0.00645 to 0.00613, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0061 - val_accuracy: 0.9987 - lr: 3.0000e-04\n",
            "Epoch 28/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 28: val_loss did not improve from 0.00613\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0068 - val_accuracy: 0.9982 - lr: 3.0000e-04\n",
            "Epoch 29/30\n",
            "2514/2519 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
            "Epoch 29: val_loss improved from 0.00613 to 0.00596, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0060 - val_accuracy: 0.9988 - lr: 3.0000e-04\n",
            "Epoch 30/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
            "Epoch 30: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0061 - val_accuracy: 0.9989 - lr: 3.0000e-04\n",
            "Epoch 1/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.2415 - accuracy: 0.9317\n",
            "Epoch 1: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.2413 - accuracy: 0.9318 - val_loss: 0.1349 - val_accuracy: 0.9615 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "2517/2519 [============================>.] - ETA: 0s - loss: 0.1030 - accuracy: 0.9693\n",
            "Epoch 2: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.1030 - accuracy: 0.9694 - val_loss: 0.0901 - val_accuracy: 0.9742 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0765 - accuracy: 0.9764\n",
            "Epoch 3: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0764 - accuracy: 0.9764 - val_loss: 0.0763 - val_accuracy: 0.9762 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9804\n",
            "Epoch 4: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0613 - accuracy: 0.9804 - val_loss: 0.0608 - val_accuracy: 0.9818 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0503 - accuracy: 0.9836\n",
            "Epoch 5: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0503 - accuracy: 0.9836 - val_loss: 0.0552 - val_accuracy: 0.9825 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "2516/2519 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 0.9857\n",
            "Epoch 6: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0425 - accuracy: 0.9857 - val_loss: 0.0452 - val_accuracy: 0.9859 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0363 - accuracy: 0.9879\n",
            "Epoch 7: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0363 - accuracy: 0.9879 - val_loss: 0.0440 - val_accuracy: 0.9867 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "2517/2519 [============================>.] - ETA: 0s - loss: 0.0320 - accuracy: 0.9889\n",
            "Epoch 8: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0320 - accuracy: 0.9889 - val_loss: 0.0357 - val_accuracy: 0.9881 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0272 - accuracy: 0.9905\n",
            "Epoch 9: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 0.0300 - val_accuracy: 0.9907 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9914\n",
            "Epoch 10: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0248 - accuracy: 0.9914 - val_loss: 0.0360 - val_accuracy: 0.9882 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0216 - accuracy: 0.9927\n",
            "Epoch 11: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0216 - accuracy: 0.9927 - val_loss: 0.0283 - val_accuracy: 0.9907 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "2514/2519 [============================>.] - ETA: 0s - loss: 0.0196 - accuracy: 0.9931\n",
            "Epoch 12: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 0.0281 - val_accuracy: 0.9909 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "2516/2519 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9939\n",
            "Epoch 13: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0183 - accuracy: 0.9939 - val_loss: 0.0200 - val_accuracy: 0.9933 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9946\n",
            "Epoch 14: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 0.0210 - val_accuracy: 0.9939 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "2511/2519 [============================>.] - ETA: 0s - loss: 0.0158 - accuracy: 0.9948\n",
            "Epoch 15: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0158 - accuracy: 0.9948 - val_loss: 0.0253 - val_accuracy: 0.9921 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "2516/2519 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9951\n",
            "Epoch 16: val_loss did not improve from 0.00596\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0148 - accuracy: 0.9951 - val_loss: 0.0233 - val_accuracy: 0.9931 - lr: 0.0010\n",
            "Epoch 17/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0061 - accuracy: 0.9982\n",
            "Epoch 17: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0061 - accuracy: 0.9982 - val_loss: 0.0103 - val_accuracy: 0.9972 - lr: 3.0000e-04\n",
            "Epoch 18/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9986\n",
            "Epoch 18: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0100 - val_accuracy: 0.9974 - lr: 3.0000e-04\n",
            "Epoch 19/30\n",
            "2516/2519 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9988\n",
            "Epoch 19: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0044 - accuracy: 0.9988 - val_loss: 0.0094 - val_accuracy: 0.9973 - lr: 3.0000e-04\n",
            "Epoch 20/30\n",
            "2508/2519 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9991\n",
            "Epoch 20: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0037 - accuracy: 0.9991 - val_loss: 0.0084 - val_accuracy: 0.9979 - lr: 3.0000e-04\n",
            "Epoch 21/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9992\n",
            "Epoch 21: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0079 - val_accuracy: 0.9979 - lr: 3.0000e-04\n",
            "Epoch 22/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 22: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0094 - val_accuracy: 0.9977 - lr: 3.0000e-04\n",
            "Epoch 23/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9992\n",
            "Epoch 23: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0080 - val_accuracy: 0.9979 - lr: 3.0000e-04\n",
            "Epoch 24/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9993\n",
            "Epoch 24: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0073 - val_accuracy: 0.9985 - lr: 3.0000e-04\n",
            "Epoch 25/30\n",
            "2508/2519 [============================>.] - ETA: 0s - loss: 0.0024 - accuracy: 0.9994\n",
            "Epoch 25: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0077 - val_accuracy: 0.9983 - lr: 3.0000e-04\n",
            "Epoch 26/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.0023 - accuracy: 0.9995\n",
            "Epoch 26: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0070 - val_accuracy: 0.9985 - lr: 3.0000e-04\n",
            "Epoch 27/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
            "Epoch 27: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0087 - val_accuracy: 0.9981 - lr: 3.0000e-04\n",
            "Epoch 28/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9994\n",
            "Epoch 28: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0067 - val_accuracy: 0.9987 - lr: 3.0000e-04\n",
            "Epoch 29/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0020 - accuracy: 0.9995\n",
            "Epoch 29: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.0076 - val_accuracy: 0.9985 - lr: 3.0000e-04\n",
            "Epoch 30/30\n",
            "2508/2519 [============================>.] - ETA: 0s - loss: 0.0021 - accuracy: 0.9995\n",
            "Epoch 30: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.0078 - val_accuracy: 0.9984 - lr: 3.0000e-04\n",
            "Epoch 1/30\n",
            "2514/2519 [============================>.] - ETA: 0s - loss: 0.2492 - accuracy: 0.9301\n",
            "Epoch 1: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.2490 - accuracy: 0.9301 - val_loss: 0.1287 - val_accuracy: 0.9601 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.1022 - accuracy: 0.9697\n",
            "Epoch 2: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.1022 - accuracy: 0.9697 - val_loss: 0.0960 - val_accuracy: 0.9700 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0761 - accuracy: 0.9765\n",
            "Epoch 3: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 12s 5ms/step - loss: 0.0761 - accuracy: 0.9765 - val_loss: 0.0703 - val_accuracy: 0.9787 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0604 - accuracy: 0.9813\n",
            "Epoch 4: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 0.0633 - val_accuracy: 0.9806 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0488 - accuracy: 0.9845\n",
            "Epoch 5: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0488 - accuracy: 0.9845 - val_loss: 0.0648 - val_accuracy: 0.9784 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0410 - accuracy: 0.9863\n",
            "Epoch 6: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0409 - accuracy: 0.9863 - val_loss: 0.0396 - val_accuracy: 0.9878 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "2508/2519 [============================>.] - ETA: 0s - loss: 0.0339 - accuracy: 0.9885\n",
            "Epoch 7: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0339 - accuracy: 0.9886 - val_loss: 0.0380 - val_accuracy: 0.9884 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "2511/2519 [============================>.] - ETA: 0s - loss: 0.0302 - accuracy: 0.9894\n",
            "Epoch 8: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0301 - accuracy: 0.9894 - val_loss: 0.0383 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.0254 - accuracy: 0.9914\n",
            "Epoch 9: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0254 - accuracy: 0.9914 - val_loss: 0.0364 - val_accuracy: 0.9890 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9919\n",
            "Epoch 10: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0231 - accuracy: 0.9919 - val_loss: 0.0286 - val_accuracy: 0.9915 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.0206 - accuracy: 0.9932\n",
            "Epoch 11: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0206 - accuracy: 0.9932 - val_loss: 0.0308 - val_accuracy: 0.9900 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "2517/2519 [============================>.] - ETA: 0s - loss: 0.0183 - accuracy: 0.9937\n",
            "Epoch 12: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0183 - accuracy: 0.9937 - val_loss: 0.0264 - val_accuracy: 0.9916 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "2514/2519 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.9940\n",
            "Epoch 13: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0205 - val_accuracy: 0.9941 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.0150 - accuracy: 0.9949\n",
            "Epoch 14: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0259 - val_accuracy: 0.9927 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "2514/2519 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9952\n",
            "Epoch 15: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0136 - accuracy: 0.9952 - val_loss: 0.0232 - val_accuracy: 0.9930 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.0130 - accuracy: 0.9957\n",
            "Epoch 16: val_loss did not improve from 0.00596\n",
            "\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0131 - accuracy: 0.9957 - val_loss: 0.0231 - val_accuracy: 0.9935 - lr: 0.0010\n",
            "Epoch 17/30\n",
            "2516/2519 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9986\n",
            "Epoch 17: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0108 - val_accuracy: 0.9975 - lr: 3.0000e-04\n",
            "Epoch 18/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9989\n",
            "Epoch 18: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0040 - accuracy: 0.9989 - val_loss: 0.0104 - val_accuracy: 0.9981 - lr: 3.0000e-04\n",
            "Epoch 19/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9989\n",
            "Epoch 19: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 0.0103 - val_accuracy: 0.9981 - lr: 3.0000e-04\n",
            "Epoch 20/30\n",
            "2516/2519 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 20: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0098 - val_accuracy: 0.9983 - lr: 3.0000e-04\n",
            "Epoch 21/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0029 - accuracy: 0.9993\n",
            "Epoch 21: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0029 - accuracy: 0.9993 - val_loss: 0.0100 - val_accuracy: 0.9981 - lr: 3.0000e-04\n",
            "Epoch 22/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0027 - accuracy: 0.9993\n",
            "Epoch 22: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0100 - val_accuracy: 0.9987 - lr: 3.0000e-04\n",
            "Epoch 23/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0022 - accuracy: 0.9995\n",
            "Epoch 23: val_loss did not improve from 0.00596\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0099 - val_accuracy: 0.9985 - lr: 3.0000e-04\n",
            "Epoch 24/30\n",
            "2514/2519 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
            "Epoch 24: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0096 - val_accuracy: 0.9988 - lr: 9.0000e-05\n",
            "Epoch 25/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9998\n",
            "Epoch 25: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0094 - val_accuracy: 0.9989 - lr: 9.0000e-05\n",
            "Epoch 26/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9998\n",
            "Epoch 26: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0093 - val_accuracy: 0.9989 - lr: 9.0000e-05\n",
            "Epoch 27/30\n",
            "2511/2519 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\n",
            "Epoch 27: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0096 - val_accuracy: 0.9988 - lr: 9.0000e-05\n",
            "Epoch 28/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\n",
            "Epoch 28: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0093 - val_accuracy: 0.9988 - lr: 9.0000e-05\n",
            "Epoch 29/30\n",
            "2511/2519 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9998\n",
            "Epoch 29: val_loss did not improve from 0.00596\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0099 - val_accuracy: 0.9988 - lr: 9.0000e-05\n",
            "Epoch 30/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 9.9183e-04 - accuracy: 0.9998\n",
            "Epoch 30: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 9.9155e-04 - accuracy: 0.9998 - val_loss: 0.0097 - val_accuracy: 0.9989 - lr: 2.7000e-05\n",
            "Epoch 1/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.2467 - accuracy: 0.9304\n",
            "Epoch 1: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.2466 - accuracy: 0.9305 - val_loss: 0.1163 - val_accuracy: 0.9675 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "2508/2519 [============================>.] - ETA: 0s - loss: 0.1023 - accuracy: 0.9696\n",
            "Epoch 2: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.1022 - accuracy: 0.9696 - val_loss: 0.0914 - val_accuracy: 0.9732 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0763 - accuracy: 0.9765\n",
            "Epoch 3: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0763 - accuracy: 0.9765 - val_loss: 0.0708 - val_accuracy: 0.9787 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0603 - accuracy: 0.9812\n",
            "Epoch 4: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0603 - accuracy: 0.9812 - val_loss: 0.0673 - val_accuracy: 0.9790 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9839\n",
            "Epoch 5: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0496 - accuracy: 0.9839 - val_loss: 0.0506 - val_accuracy: 0.9845 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0418 - accuracy: 0.9861\n",
            "Epoch 6: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0418 - accuracy: 0.9861 - val_loss: 0.0425 - val_accuracy: 0.9862 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0353 - accuracy: 0.9881\n",
            "Epoch 7: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0353 - accuracy: 0.9881 - val_loss: 0.0374 - val_accuracy: 0.9880 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "2516/2519 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9898\n",
            "Epoch 8: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0304 - accuracy: 0.9898 - val_loss: 0.0329 - val_accuracy: 0.9893 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9915\n",
            "Epoch 9: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0256 - accuracy: 0.9915 - val_loss: 0.0287 - val_accuracy: 0.9913 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9922\n",
            "Epoch 10: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0246 - val_accuracy: 0.9919 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9933\n",
            "Epoch 11: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0256 - val_accuracy: 0.9919 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "2516/2519 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9939\n",
            "Epoch 12: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.0268 - val_accuracy: 0.9922 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0170 - accuracy: 0.9944\n",
            "Epoch 13: val_loss did not improve from 0.00596\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0250 - val_accuracy: 0.9922 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "2511/2519 [============================>.] - ETA: 0s - loss: 0.0076 - accuracy: 0.9977\n",
            "Epoch 14: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0076 - accuracy: 0.9977 - val_loss: 0.0111 - val_accuracy: 0.9968 - lr: 3.0000e-04\n",
            "Epoch 15/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9984\n",
            "Epoch 15: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0058 - accuracy: 0.9984 - val_loss: 0.0103 - val_accuracy: 0.9970 - lr: 3.0000e-04\n",
            "Epoch 16/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9985\n",
            "Epoch 16: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0052 - accuracy: 0.9985 - val_loss: 0.0088 - val_accuracy: 0.9977 - lr: 3.0000e-04\n",
            "Epoch 17/30\n",
            "2508/2519 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9988\n",
            "Epoch 17: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0045 - accuracy: 0.9988 - val_loss: 0.0084 - val_accuracy: 0.9976 - lr: 3.0000e-04\n",
            "Epoch 18/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9989\n",
            "Epoch 18: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0041 - accuracy: 0.9990 - val_loss: 0.0071 - val_accuracy: 0.9979 - lr: 3.0000e-04\n",
            "Epoch 19/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9990\n",
            "Epoch 19: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0082 - val_accuracy: 0.9983 - lr: 3.0000e-04\n",
            "Epoch 20/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9990\n",
            "Epoch 20: val_loss did not improve from 0.00596\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0078 - val_accuracy: 0.9981 - lr: 3.0000e-04\n",
            "Epoch 21/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9992\n",
            "Epoch 21: val_loss did not improve from 0.00596\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0075 - val_accuracy: 0.9983 - lr: 3.0000e-04\n",
            "Epoch 22/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0019 - accuracy: 0.9997\n",
            "Epoch 22: val_loss improved from 0.00596 to 0.00586, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0019 - accuracy: 0.9997 - val_loss: 0.0059 - val_accuracy: 0.9988 - lr: 9.0000e-05\n",
            "Epoch 23/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.0017 - accuracy: 0.9996\n",
            "Epoch 23: val_loss improved from 0.00586 to 0.00532, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0053 - val_accuracy: 0.9988 - lr: 9.0000e-05\n",
            "Epoch 24/30\n",
            "2514/2519 [============================>.] - ETA: 0s - loss: 0.0017 - accuracy: 0.9997\n",
            "Epoch 24: val_loss did not improve from 0.00532\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0056 - val_accuracy: 0.9987 - lr: 9.0000e-05\n",
            "Epoch 25/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9997\n",
            "Epoch 25: val_loss did not improve from 0.00532\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0059 - val_accuracy: 0.9987 - lr: 9.0000e-05\n",
            "Epoch 26/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
            "Epoch 26: val_loss did not improve from 0.00532\n",
            "\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0059 - val_accuracy: 0.9986 - lr: 9.0000e-05\n",
            "Epoch 27/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0013 - accuracy: 0.9997\n",
            "Epoch 27: val_loss did not improve from 0.00532\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0054 - val_accuracy: 0.9987 - lr: 2.7000e-05\n",
            "Epoch 28/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 28: val_loss improved from 0.00532 to 0.00531, saving model to mdl_wts_race.hdf5\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0053 - val_accuracy: 0.9988 - lr: 2.7000e-05\n",
            "Epoch 29/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 29: val_loss improved from 0.00531 to 0.00528, saving model to mdl_wts_race.hdf5\n",
            "\n",
            "Epoch 29: ReduceLROnPlateau reducing learning rate to 8.100000013655517e-06.\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0053 - val_accuracy: 0.9988 - lr: 2.7000e-05\n",
            "Epoch 30/30\n",
            "2508/2519 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 30: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 13s 5ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0053 - val_accuracy: 0.9988 - lr: 8.1000e-06\n",
            "Epoch 1/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.2436 - accuracy: 0.9312\n",
            "Epoch 1: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.2431 - accuracy: 0.9313 - val_loss: 0.1176 - val_accuracy: 0.9641 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "2511/2519 [============================>.] - ETA: 0s - loss: 0.1016 - accuracy: 0.9698\n",
            "Epoch 2: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.1016 - accuracy: 0.9698 - val_loss: 0.0929 - val_accuracy: 0.9706 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0758 - accuracy: 0.9762\n",
            "Epoch 3: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0758 - accuracy: 0.9762 - val_loss: 0.0671 - val_accuracy: 0.9784 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "2517/2519 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.9807\n",
            "Epoch 4: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0609 - accuracy: 0.9807 - val_loss: 0.0513 - val_accuracy: 0.9832 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "2514/2519 [============================>.] - ETA: 0s - loss: 0.0493 - accuracy: 0.9840\n",
            "Epoch 5: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0493 - accuracy: 0.9840 - val_loss: 0.0488 - val_accuracy: 0.9841 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9864\n",
            "Epoch 6: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0419 - accuracy: 0.9864 - val_loss: 0.0406 - val_accuracy: 0.9866 - lr: 0.0010\n",
            "Epoch 7/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0368 - accuracy: 0.9878\n",
            "Epoch 7: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0368 - accuracy: 0.9878 - val_loss: 0.0333 - val_accuracy: 0.9884 - lr: 0.0010\n",
            "Epoch 8/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9896\n",
            "Epoch 8: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0306 - accuracy: 0.9896 - val_loss: 0.0363 - val_accuracy: 0.9882 - lr: 0.0010\n",
            "Epoch 9/30\n",
            "2517/2519 [============================>.] - ETA: 0s - loss: 0.0269 - accuracy: 0.9909\n",
            "Epoch 9: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0269 - accuracy: 0.9909 - val_loss: 0.0353 - val_accuracy: 0.9883 - lr: 0.0010\n",
            "Epoch 10/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0235 - accuracy: 0.9921\n",
            "Epoch 10: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0235 - accuracy: 0.9921 - val_loss: 0.0266 - val_accuracy: 0.9913 - lr: 0.0010\n",
            "Epoch 11/30\n",
            "2511/2519 [============================>.] - ETA: 0s - loss: 0.0206 - accuracy: 0.9931\n",
            "Epoch 11: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0206 - accuracy: 0.9931 - val_loss: 0.0341 - val_accuracy: 0.9883 - lr: 0.0010\n",
            "Epoch 12/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0193 - accuracy: 0.9934\n",
            "Epoch 12: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.0196 - val_accuracy: 0.9935 - lr: 0.0010\n",
            "Epoch 13/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9945\n",
            "Epoch 13: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0213 - val_accuracy: 0.9927 - lr: 0.0010\n",
            "Epoch 14/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9945\n",
            "Epoch 14: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0159 - accuracy: 0.9945 - val_loss: 0.0249 - val_accuracy: 0.9914 - lr: 0.0010\n",
            "Epoch 15/30\n",
            "2511/2519 [============================>.] - ETA: 0s - loss: 0.0147 - accuracy: 0.9950\n",
            "Epoch 15: val_loss did not improve from 0.00528\n",
            "\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 0.0255 - val_accuracy: 0.9908 - lr: 0.0010\n",
            "Epoch 16/30\n",
            "2517/2519 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9981\n",
            "Epoch 16: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0066 - accuracy: 0.9981 - val_loss: 0.0093 - val_accuracy: 0.9975 - lr: 3.0000e-04\n",
            "Epoch 17/30\n",
            "2511/2519 [============================>.] - ETA: 0s - loss: 0.0052 - accuracy: 0.9984\n",
            "Epoch 17: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0052 - accuracy: 0.9984 - val_loss: 0.0082 - val_accuracy: 0.9979 - lr: 3.0000e-04\n",
            "Epoch 18/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0044 - accuracy: 0.9986\n",
            "Epoch 18: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.0093 - val_accuracy: 0.9979 - lr: 3.0000e-04\n",
            "Epoch 19/30\n",
            "2514/2519 [============================>.] - ETA: 0s - loss: 0.0040 - accuracy: 0.9988\n",
            "Epoch 19: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0082 - val_accuracy: 0.9983 - lr: 3.0000e-04\n",
            "Epoch 20/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0035 - accuracy: 0.9991\n",
            "Epoch 20: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0035 - accuracy: 0.9991 - val_loss: 0.0073 - val_accuracy: 0.9985 - lr: 3.0000e-04\n",
            "Epoch 21/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0032 - accuracy: 0.9991\n",
            "Epoch 21: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0087 - val_accuracy: 0.9976 - lr: 3.0000e-04\n",
            "Epoch 22/30\n",
            "2518/2519 [============================>.] - ETA: 0s - loss: 0.0031 - accuracy: 0.9991\n",
            "Epoch 22: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0072 - val_accuracy: 0.9988 - lr: 3.0000e-04\n",
            "Epoch 23/30\n",
            "2519/2519 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9993\n",
            "Epoch 23: val_loss did not improve from 0.00528\n",
            "\n",
            "Epoch 23: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0081 - val_accuracy: 0.9986 - lr: 3.0000e-04\n",
            "Epoch 24/30\n",
            "2510/2519 [============================>.] - ETA: 0s - loss: 0.0016 - accuracy: 0.9997\n",
            "Epoch 24: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0063 - val_accuracy: 0.9991 - lr: 9.0000e-05\n",
            "Epoch 25/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9997\n",
            "Epoch 25: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9992 - lr: 9.0000e-05\n",
            "Epoch 26/30\n",
            "2512/2519 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
            "Epoch 26: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 0.9990 - lr: 9.0000e-05\n",
            "Epoch 27/30\n",
            "2513/2519 [============================>.] - ETA: 0s - loss: 0.0014 - accuracy: 0.9997\n",
            "Epoch 27: val_loss did not improve from 0.00528\n",
            "\n",
            "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "2519/2519 [==============================] - 14s 5ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 0.9991 - lr: 9.0000e-05\n",
            "Epoch 28/30\n",
            "2515/2519 [============================>.] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997\n",
            "Epoch 28: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0062 - val_accuracy: 0.9990 - lr: 2.7000e-05\n",
            "Epoch 29/30\n",
            "2509/2519 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997\n",
            "Epoch 29: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 14s 6ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0061 - val_accuracy: 0.9991 - lr: 2.7000e-05\n",
            "Epoch 30/30\n",
            "2516/2519 [============================>.] - ETA: 0s - loss: 0.0011 - accuracy: 0.9998\n",
            "Epoch 30: val_loss did not improve from 0.00528\n",
            "2519/2519 [==============================] - 15s 6ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0062 - val_accuracy: 0.9991 - lr: 2.7000e-05\n",
            "[[[4.00392e+04 0.00000e+00]\n",
            "  [0.00000e+00 2.60000e+02]]\n",
            "\n",
            " [[3.74350e+04 5.40000e+00]\n",
            "  [1.22000e+01 2.84660e+03]]\n",
            "\n",
            " [[3.74254e+04 2.80000e+00]\n",
            "  [8.00000e+00 2.86300e+03]]\n",
            "\n",
            " [[3.52746e+04 2.20000e+00]\n",
            "  [1.80000e+00 5.02060e+03]]\n",
            "\n",
            " [[3.34968e+04 3.00000e+00]\n",
            "  [1.00000e+00 6.79840e+03]]\n",
            "\n",
            " [[3.89164e+04 0.00000e+00]\n",
            "  [2.40000e+00 1.38040e+03]]\n",
            "\n",
            " [[3.49722e+04 2.30000e+01]\n",
            "  [1.00000e+01 5.29400e+03]]\n",
            "\n",
            " [[3.50678e+04 3.20000e+00]\n",
            "  [5.40000e+00 5.22280e+03]]\n",
            "\n",
            " [[3.81168e+04 6.00000e-01]\n",
            "  [1.40000e+00 2.18040e+03]]\n",
            "\n",
            " [[3.88180e+04 2.00000e+00]\n",
            "  [1.80000e+00 1.47740e+03]]\n",
            "\n",
            " [[3.95896e+04 6.00000e-01]\n",
            "  [0.00000e+00 7.09000e+02]]\n",
            "\n",
            " [[3.96750e+04 6.00000e-01]\n",
            "  [6.00000e-01 6.23000e+02]]\n",
            "\n",
            " [[3.97168e+04 6.00000e-01]\n",
            "  [1.20000e+00 5.80600e+02]]\n",
            "\n",
            " [[3.96844e+04 1.20000e+00]\n",
            "  [0.00000e+00 6.13600e+02]]\n",
            "\n",
            " [[3.95506e+04 1.20000e+00]\n",
            "  [8.00000e-01 7.46600e+02]]\n",
            "\n",
            " [[3.97020e+04 0.00000e+00]\n",
            "  [0.00000e+00 5.97200e+02]]\n",
            "\n",
            " [[4.01256e+04 0.00000e+00]\n",
            "  [0.00000e+00 1.73600e+02]]\n",
            "\n",
            " [[3.98984e+04 6.00000e-01]\n",
            "  [0.00000e+00 4.00200e+02]]\n",
            "\n",
            " [[3.98316e+04 1.20000e+00]\n",
            "  [8.00000e-01 4.65600e+02]]\n",
            "\n",
            " [[3.94406e+04 0.00000e+00]\n",
            "  [0.00000e+00 8.58600e+02]]\n",
            "\n",
            " [[3.98092e+04 0.00000e+00]\n",
            "  [0.00000e+00 4.90000e+02]]\n",
            "\n",
            " [[3.96490e+04 0.00000e+00]\n",
            "  [8.00000e-01 6.49400e+02]]]\n",
            "cnn accuracy score:  0.9988039460861327\n",
            "cnn recall score:  [1.         0.99575964 0.99722128 0.99964432 0.99985202 0.9982218\n",
            " 0.99810998 0.99897051 0.99935576 0.99879325 1.         0.99901478\n",
            " 0.99786434 1.         0.99887798 1.         1.         1.\n",
            " 0.99829424 1.         1.         0.99881129]\n",
            "cnn presion score:  [1.         0.99809523 0.99902149 0.99956386 0.99955733 1.\n",
            " 0.99568071 0.99938914 0.99972452 0.99867782 0.99913043 0.99905808\n",
            " 0.99894552 0.99802045 0.99833986 1.         1.         0.99849624\n",
            " 0.99740431 1.         1.         1.        ]\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from sklearn.metrics import classification_report \n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D, BatchNormalization, Flatten, Dropout\n",
        "from tensorflow.keras.layers import Input,Activation,Add\n",
        "import tensorflow.keras.layers as layers\n",
        "import keras\n",
        "\n",
        "checkpointer = ModelCheckpoint('mdl_wts_race.hdf5', monitor='val_loss',verbose=1,save_best_only=True,save_weights_only=False, mode='auto',save_freq='epoch')\n",
        "Early_stop=EarlyStopping(patience=30, monitor='val_loss',restore_best_weights=True)\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=1, epsilon=1e-4, mode='auto')\n",
        "callback_list=[checkpointer,Early_stop, reduce_lr_loss]\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "cnn_cm = np.zeros((22, 2, 2))\n",
        "cnn_accuracy = 0\n",
        "cnn_recall = 0\n",
        "cnn_precision = 0\n",
        "\n",
        "for train_index, test_index in kf.split(shuffle_img):\n",
        "\n",
        "  model_ = Sequential()\n",
        "  model_.add(Input(shape=(45,45,1)))\n",
        "  #model_.add(data_augmentation)\n",
        "  model_.add(layers.experimental.preprocessing.Rescaling(1.0 / 255))\n",
        "  model_.add(Conv2D(16, kernel_size=(3, 3), activation='relu'))\n",
        "  model_.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model_.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "  model_.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model_.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model_.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  #model_.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  #model_.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model_.add(Flatten())\n",
        "  #model_.add(Dense(1024, activation='relu'))\n",
        "  model_.add(Dense(22, activation='softmax'))\n",
        "\n",
        "  #model_ = Model(input, output)\n",
        "  model_.compile(loss=[\"categorical_crossentropy\"], optimizer=\"Adam\", metrics=[\"accuracy\"])\n",
        "  hist = model_.fit(shuffle_img[train_index],encoded[train_index], validation_data=(shuffle_img[test_index], encoded[test_index]), batch_size=64,epochs=30,callbacks=[callback_list])\n",
        "\n",
        "  tmp = model_.predict(shuffle_img[test_index])\n",
        "\n",
        "  cnn_cm = np.add(cnn_cm, multilabel_confusion_matrix(np.argmax(encoded[test_index], axis = 1), np.argmax(tmp, axis = 1)))\n",
        "  cnn_accuracy += accuracy_score(np.argmax(encoded[test_index], axis = 1), np.argmax(tmp, axis = 1))\n",
        "  cnn_recall += recall_score(np.argmax(encoded[test_index], axis = 1), np.argmax(tmp, axis = 1), average=None)\n",
        "  cnn_precision += precision_score(np.argmax(encoded[test_index], axis = 1), np.argmax(tmp, axis = 1), average=None)\n",
        "\n",
        "cnn_cm /= 5 \n",
        "#np.round(cm)\n",
        "cnn_accuracy /= 5\n",
        "cnn_recall /= 5\n",
        "cnn_precision /= 5\n",
        "print(cnn_cm)\n",
        "print(\"cnn accuracy score: \", cnn_accuracy)\n",
        "print(\"cnn recall score: \", cnn_recall)\n",
        "print(\"cnn presion score: \", cnn_precision)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uTwkzTksMp5",
        "outputId": "f7664898-8ad3-44f9-fe9c-6a9e1327718d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling_10 (Rescaling)    (None, 45, 45, 1)         0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 43, 43, 16)        160       \n",
            "                                                                 \n",
            " max_pooling2d_30 (MaxPoolin  (None, 21, 21, 16)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 19, 19, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_31 (MaxPoolin  (None, 9, 9, 32)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 7, 7, 64)          18496     \n",
            "                                                                 \n",
            " max_pooling2d_32 (MaxPoolin  (None, 3, 3, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_10 (Flatten)        (None, 576)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 22)                12694     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 35,990\n",
            "Trainable params: 35,990\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(model_.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0oe8LkNPI0D"
      },
      "outputs": [],
      "source": [
        "model_json = model_.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model_.save_weights(\"model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30PnIGcXJywh"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "def predict(symbol):\n",
        "  model = keras.models.load_model('mdl_wts_race.hdf5')\n",
        "  pred = model.predict(symbol)\n",
        "  return pred"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "AI final project.ipynb ",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
